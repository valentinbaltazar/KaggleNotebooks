{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.15","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":9512215,"sourceType":"datasetVersion","datasetId":5790268},{"sourceId":9562421,"sourceType":"datasetVersion","datasetId":5827474},{"sourceId":9653586,"sourceType":"datasetVersion","datasetId":5791295},{"sourceId":11371,"sourceType":"modelInstanceVersion","modelInstanceId":5171,"modelId":3533},{"sourceId":11372,"sourceType":"modelInstanceVersion","modelInstanceId":5388,"modelId":3533}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Modify inputs here\ntune_size = 1_00\nmax_dataset_size = 'full' #20_000 # leads to about ~1M sequences for inference\n\n# model_name = \"gemma_instruct_2b_en\"\nmodel_name = \"gemma_2b_en\"\n# lora_h5 = \"gemma_2b_enV2-100\"\ntotal_epochs = 1 # from training\nmax_seq_len = 13\n\n\n# Set max_char length for model out here\nmax_char_output = 128 # 64 ~seq length 11\nmax_char_input = 128\n\n# Set batch size for memory opt\nbatch_size = 200 # 300\n\nGPU = 'TPU'\nfile_name = f'lora_infer_{tune_size}pgn-{model_name}-{total_epochs}e-{max_seq_len}len-{max_dataset_size}set-{GPU}-{max_char_output}ch.pkl'\nLORA_WEIGHTS_PATH = \"/kaggle/input/lora-updated-chess-llm/gemma_2b_en-100pgn-1e-12len-TPU.lora.h5\"","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:11:19.730815Z","iopub.execute_input":"2024-10-19T00:11:19.731513Z","iopub.status.idle":"2024-10-19T00:11:19.736162Z","shell.execute_reply.started":"2024-10-19T00:11:19.731479Z","shell.execute_reply":"2024-10-19T00:11:19.735260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"# Install Keras\n# !pip install -q -U keras-nlp\n# !pip install -q -U keras>=3\n\n!pip install -q tensorflow-cpu\n!pip install -q -U keras-nlp tensorflow-hub\n!pip install -q -U keras>=3\n!pip install -q -U tensorflow-text","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:00:04.417926Z","iopub.execute_input":"2024-10-19T00:00:04.418175Z","iopub.status.idle":"2024-10-19T00:01:47.235301Z","shell.execute_reply.started":"2024-10-19T00:00:04.418149Z","shell.execute_reply":"2024-10-19T00:01:47.234254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nos.environ[\"KERAS_BACKEND\"] = \"jax\"  # Or \"torch\" or \"tensorflow\".\n# Avoid memory fragmentation on JAX backend.\nos.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.0\"","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:04:22.131428Z","iopub.execute_input":"2024-10-19T00:04:22.131904Z","iopub.status.idle":"2024-10-19T00:04:22.135858Z","shell.execute_reply.started":"2024-10-19T00:04:22.131862Z","shell.execute_reply":"2024-10-19T00:04:22.135182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nimport keras_nlp\n\n# Load the model\ngemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:04:22.486778Z","iopub.execute_input":"2024-10-19T00:04:22.487612Z","iopub.status.idle":"2024-10-19T00:05:37.015434Z","shell.execute_reply.started":"2024-10-19T00:04:22.487577Z","shell.execute_reply":"2024-10-19T00:05:37.014337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gemma_lm.summary()","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:05:37.017228Z","iopub.execute_input":"2024-10-19T00:05:37.017751Z","iopub.status.idle":"2024-10-19T00:05:37.043451Z","shell.execute_reply.started":"2024-10-19T00:05:37.017718Z","shell.execute_reply":"2024-10-19T00:05:37.042636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Enable LoRA for the model and set the LoRA rank to 4.\ngemma_lm.backbone.enable_lora(rank=4)\ngemma_lm.summary()","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:05:37.044551Z","iopub.execute_input":"2024-10-19T00:05:37.044823Z","iopub.status.idle":"2024-10-19T00:05:37.848595Z","shell.execute_reply.started":"2024-10-19T00:05:37.044796Z","shell.execute_reply":"2024-10-19T00:05:37.847546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LoRA Weights","metadata":{}},{"cell_type":"code","source":"# Limit the input sequence length to 512 (to control memory usage).\n# gemma_lm.preprocessor.sequence_length = 512\ngemma_lm.preprocessor.sequence_length = max_char_input\n\n\n# Define paths\n# model_name = \"gemma_2b_enV2-100\"\n# model_name = \"gemma_2b_enV2-1k\"\n\n# LORA_WEIGHTS_PATH = f\"/kaggle/input/lora-updated-chess-llm/{lora_h5}\"\n\n# Load only the lora weights\ngemma_lm.backbone.load_lora_weights(LORA_WEIGHTS_PATH)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:06:33.552326Z","iopub.execute_input":"2024-10-19T00:06:33.553283Z","iopub.status.idle":"2024-10-19T00:06:33.867371Z","shell.execute_reply.started":"2024-10-19T00:06:33.553226Z","shell.execute_reply":"2024-10-19T00:06:33.866604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test Set","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndf0 = pd.read_pickle('/kaggle/input/60k-chess-clean/club_games_data.pkl')\n\ndf0.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:06:51.537618Z","iopub.execute_input":"2024-10-19T00:06:51.538391Z","iopub.status.idle":"2024-10-19T00:06:53.729836Z","shell.execute_reply.started":"2024-10-19T00:06:51.538358Z","shell.execute_reply":"2024-10-19T00:06:53.729003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df0.info()","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:06:53.731130Z","iopub.execute_input":"2024-10-19T00:06:53.731413Z","iopub.status.idle":"2024-10-19T00:06:53.786815Z","shell.execute_reply.started":"2024-10-19T00:06:53.731387Z","shell.execute_reply":"2024-10-19T00:06:53.786019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df0[df0['rules']=='chess'].dropna() # Classic chess only, and drop None","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:06:53.787712Z","iopub.execute_input":"2024-10-19T00:06:53.787987Z","iopub.status.idle":"2024-10-19T00:06:53.864264Z","shell.execute_reply.started":"2024-10-19T00:06:53.787959Z","shell.execute_reply":"2024-10-19T00:06:53.863331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:06:53.865696Z","iopub.execute_input":"2024-10-19T00:06:53.865941Z","iopub.status.idle":"2024-10-19T00:06:53.912760Z","shell.execute_reply.started":"2024-10-19T00:06:53.865916Z","shell.execute_reply":"2024-10-19T00:06:53.911808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reduce size of dataset\n\nToo large, need to reduce since we have limited GPU time","metadata":{}},{"cell_type":"code","source":"# truncate dataset size, 20k is about 1M sequences\nif max_dataset_size != 'full':\n    df = df.sample(n=max_dataset_size)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:07:09.045940Z","iopub.execute_input":"2024-10-19T00:07:09.046510Z","iopub.status.idle":"2024-10-19T00:07:09.050133Z","shell.execute_reply.started":"2024-10-19T00:07:09.046480Z","shell.execute_reply":"2024-10-19T00:07:09.049317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# tune_size = 1_000 # Number of pgn samples to use in tuning\nmin_elo = 1_000 # I want the model to tune on the better half of players\n\n\ndf_low_elo = df[df['white_rating']<min_elo]\n\ndf = df[df['white_rating']>=min_elo]\n\n\nX = df.drop('white_rating', axis=1)\ny = df['white_rating']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=tune_size, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:07:09.053569Z","iopub.execute_input":"2024-10-19T00:07:09.053814Z","iopub.status.idle":"2024-10-19T00:07:10.157771Z","shell.execute_reply.started":"2024-10-19T00:07:09.053789Z","shell.execute_reply":"2024-10-19T00:07:10.156664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(X_train),len(X_test))","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:07:10.159256Z","iopub.execute_input":"2024-10-19T00:07:10.159906Z","iopub.status.idle":"2024-10-19T00:07:10.163994Z","shell.execute_reply.started":"2024-10-19T00:07:10.159866Z","shell.execute_reply":"2024-10-19T00:07:10.163189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(df_low_elo))","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:07:10.164941Z","iopub.execute_input":"2024-10-19T00:07:10.165224Z","iopub.status.idle":"2024-10-19T00:07:10.176643Z","shell.execute_reply.started":"2024-10-19T00:07:10.165194Z","shell.execute_reply":"2024-10-19T00:07:10.175925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will use the test set as the high elo test, and then the filtered lower elo as another test set.","metadata":{}},{"cell_type":"code","source":"def seq_set(seq_data, n):\n    # List of all UNIQUE sequences of length < n in a given dataset of moves\n    sequences = set()\n    \n    for seq in seq_data:\n        max_n = n if len(seq) >= n else len(seq)\n        #sequences.update(seq[:t] for t in range(1,max_n+1))\n        # Minor edit to allow for full sequnces of max length, excludes check mates\n        sequences.update(seq[:t] for t in range(1,max_n))\n\n\n    return sequences\n        \n# Trained on n=6, max seq of 5 and asked to predict 6th\ntest_seq_input = [('e4', 'c5', 'b3', 'Nc6', 'a4', 'Nf6#')]\nprint(test_seq_input)\nprint(seq_set(test_seq_input, 1_000))","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:07:10.178232Z","iopub.execute_input":"2024-10-19T00:07:10.178509Z","iopub.status.idle":"2024-10-19T00:07:10.188123Z","shell.execute_reply.started":"2024-10-19T00:07:10.178484Z","shell.execute_reply":"2024-10-19T00:07:10.187424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Set max seq length ","metadata":{}},{"cell_type":"code","source":"low_elo_seq = seq_set(df_low_elo['move_seq'], max_seq_len)\nlen(low_elo_seq)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:07:10.188966Z","iopub.execute_input":"2024-10-19T00:07:10.189208Z","iopub.status.idle":"2024-10-19T00:07:10.291053Z","shell.execute_reply.started":"2024-10-19T00:07:10.189182Z","shell.execute_reply":"2024-10-19T00:07:10.290252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"high_elo_seq = seq_set(X_test['move_seq'], max_seq_len)\nlen(high_elo_seq)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:07:10.291981Z","iopub.execute_input":"2024-10-19T00:07:10.292229Z","iopub.status.idle":"2024-10-19T00:07:10.576782Z","shell.execute_reply.started":"2024-10-19T00:07:10.292204Z","shell.execute_reply":"2024-10-19T00:07:10.575930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"intersect = low_elo_seq & high_elo_seq\n\nlen(intersect)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:07:10.577639Z","iopub.execute_input":"2024-10-19T00:07:10.577873Z","iopub.status.idle":"2024-10-19T00:07:10.596367Z","shell.execute_reply.started":"2024-10-19T00:07:10.577848Z","shell.execute_reply":"2024-10-19T00:07:10.595561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"low_set = low_elo_seq - high_elo_seq\nlen(low_set)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:07:10.597176Z","iopub.execute_input":"2024-10-19T00:07:10.597420Z","iopub.status.idle":"2024-10-19T00:07:10.626005Z","shell.execute_reply.started":"2024-10-19T00:07:10.597395Z","shell.execute_reply":"2024-10-19T00:07:10.625229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"high_set = high_elo_seq - low_elo_seq\nlen(high_set)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:07:10.626828Z","iopub.execute_input":"2024-10-19T00:07:10.627088Z","iopub.status.idle":"2024-10-19T00:07:10.675382Z","shell.execute_reply.started":"2024-10-19T00:07:10.627061Z","shell.execute_reply":"2024-10-19T00:07:10.674516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Total Size of Inference Set","metadata":{}},{"cell_type":"code","source":"total_size = len(high_set) + len(low_set) + len(intersect)\n\nprint(f\"{total_size:,}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:07:10.677889Z","iopub.execute_input":"2024-10-19T00:07:10.678171Z","iopub.status.idle":"2024-10-19T00:07:10.684754Z","shell.execute_reply.started":"2024-10-19T00:07:10.678146Z","shell.execute_reply":"2024-10-19T00:07:10.684010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Metrics Dataset","metadata":{}},{"cell_type":"code","source":"import time\n\ndef time_wrapper(func):\n    def wrapper(*args, **kwargs):\n        start_time = time.time()  # Record the start time\n        result = func(*args, **kwargs)  # Call the original function\n        end_time = time.time()  # Record the end time\n        print(f\"Execution time: {end_time - start_time:.4f} seconds\")\n        return result\n    return wrapper","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:07:10.685611Z","iopub.execute_input":"2024-10-19T00:07:10.685853Z","iopub.status.idle":"2024-10-19T00:07:10.694175Z","shell.execute_reply.started":"2024-10-19T00:07:10.685827Z","shell.execute_reply":"2024-10-19T00:07:10.693521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def apply_format(seq):\n    prompt = \"Instruction:\\n{instruction}\\n\\nResponse:\\n{response}\".format(\n            instruction=f\"Predict the next chess move in the sequence {str(list(seq))}\",\n            response=\"\",\n        )\n    return prompt\n\n\n@time_wrapper\ndef batch_prompt(seq_list):\n    batch_prompts = list(map(apply_format, seq_list))\n    \n    output = gemma_lm.generate(batch_prompts, max_length=max_char_output)\n    #print(output)\n    #seq.append(output.split(' ')[-1].strip(\"'\"))\n    #print(output)\n    return output\n","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:07:10.695001Z","iopub.execute_input":"2024-10-19T00:07:10.695251Z","iopub.status.idle":"2024-10-19T00:07:10.703402Z","shell.execute_reply.started":"2024-10-19T00:07:10.695224Z","shell.execute_reply":"2024-10-19T00:07:10.702752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_and_return(lst, n):\n    result = lst[:n]\n    del lst[:n]\n    \n    return result\n\nmy_list = [1, 2, 3, 4, 5, 6, 7, 8]\nprint(remove_and_return(my_list, 3))  # Output: [1, 2, 3]\nprint(my_list)  # Output: [4, 5]","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:07:10.704384Z","iopub.execute_input":"2024-10-19T00:07:10.704623Z","iopub.status.idle":"2024-10-19T00:07:10.716029Z","shell.execute_reply.started":"2024-10-19T00:07:10.704598Z","shell.execute_reply":"2024-10-19T00:07:10.715257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def segment_all(seq_list, batch_size):\n    data = seq_list.copy()\n    final_output = []\n    while len(data) > 0:\n        batch = remove_and_return(data, batch_size)\n        final_output.append(batch)\n    return final_output\n        \n        \n# test = segment_all(list(intersect)[:1000], 300)\n\n# print(len(test))","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:07:10.716868Z","iopub.execute_input":"2024-10-19T00:07:10.717292Z","iopub.status.idle":"2024-10-19T00:07:10.724575Z","shell.execute_reply.started":"2024-10-19T00:07:10.717252Z","shell.execute_reply":"2024-10-19T00:07:10.723797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_all(seq_set, n):\n    all_res = []\n    segments = segment_all(list(seq_set), n)\n    for sample in segments:\n        res = batch_prompt(sample)\n        all_res.append((sample,  res))\n    return all_res","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:07:10.725412Z","iopub.execute_input":"2024-10-19T00:07:10.725652Z","iopub.status.idle":"2024-10-19T00:07:10.733510Z","shell.execute_reply.started":"2024-10-19T00:07:10.725625Z","shell.execute_reply":"2024-10-19T00:07:10.732839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inter_res = run_all(intersect, batch_size)\n\nprint(len(inter_res))","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:09:46.964064Z","iopub.execute_input":"2024-10-19T00:09:46.964458Z","iopub.status.idle":"2024-10-19T00:10:28.908100Z","shell.execute_reply.started":"2024-10-19T00:09:46.964426Z","shell.execute_reply":"2024-10-19T00:10:28.906523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_sample = 22\nprint(inter_res[0][0][n_sample])\nprint(inter_res[0][1][n_sample])","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:07:27.060306Z","iopub.status.idle":"2024-10-19T00:07:27.060613Z","shell.execute_reply.started":"2024-10-19T00:07:27.060452Z","shell.execute_reply":"2024-10-19T00:07:27.060466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"high_res = run_all(high_set, batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:07:27.061810Z","iopub.status.idle":"2024-10-19T00:07:27.062105Z","shell.execute_reply.started":"2024-10-19T00:07:27.061963Z","shell.execute_reply":"2024-10-19T00:07:27.061977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"low_res = run_all(low_set, batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:07:27.062922Z","iopub.status.idle":"2024-10-19T00:07:27.063200Z","shell.execute_reply.started":"2024-10-19T00:07:27.063062Z","shell.execute_reply":"2024-10-19T00:07:27.063076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save Results\n\nSave the output for each given sequence of the type high, low, inter","metadata":{}},{"cell_type":"code","source":"def to_df(data, name):\n    sample_df = pd.DataFrame(data)\n    sample_df[\"elo\"] = name\n    sample_df.columns = ['seq', 'res', 'elo']\n    return sample_df","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:07:27.064341Z","iopub.status.idle":"2024-10-19T00:07:27.064640Z","shell.execute_reply.started":"2024-10-19T00:07:27.064490Z","shell.execute_reply":"2024-10-19T00:07:27.064505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inter_df = to_df(inter_res,'inter')\nhigh_df = to_df(high_res,'high')\nlow_df = to_df(low_res,'low')","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:07:27.065526Z","iopub.status.idle":"2024-10-19T00:07:27.065873Z","shell.execute_reply.started":"2024-10-19T00:07:27.065707Z","shell.execute_reply":"2024-10-19T00:07:27.065724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_df = pd.concat([inter_df, high_df, low_df])","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:07:27.066825Z","iopub.status.idle":"2024-10-19T00:07:27.067160Z","shell.execute_reply.started":"2024-10-19T00:07:27.066997Z","shell.execute_reply":"2024-10-19T00:07:27.067014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tune_size)\nprint(model_name)\n\n# file_name = f'lora_infer_{tune_size}.pkl'\nfinal_df.to_pickle(f'/kaggle/working/{file_name}')","metadata":{"execution":{"iopub.status.busy":"2024-10-19T00:07:27.068054Z","iopub.status.idle":"2024-10-19T00:07:27.068351Z","shell.execute_reply.started":"2024-10-19T00:07:27.068193Z","shell.execute_reply":"2024-10-19T00:07:27.068207Z"},"trusted":true},"execution_count":null,"outputs":[]}]}